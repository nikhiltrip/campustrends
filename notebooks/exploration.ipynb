{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f69f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# These are the standard tools for data analysis in Python\n",
    "\n",
    "import pandas as pd  # For working with tabular data (like spreadsheets)\n",
    "import numpy as np  # For numerical operations and arrays\n",
    "import matplotlib.pyplot as plt  # For creating visualizations\n",
    "import seaborn as sns  # For beautiful statistical plots\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configure visualization settings\n",
    "# This makes our plots look nicer and easier to read\n",
    "sns.set_style('whitegrid')  # Use a clean grid background\n",
    "plt.rcParams['figure.figsize'] = (12, 6)  # Default figure size\n",
    "plt.rcParams['font.size'] = 10  # Default font size\n",
    "\n",
    "# Display all columns in pandas (don't truncate)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c61f968",
   "metadata": {},
   "source": [
    "## Step 1: Load Sample Data\n",
    "\n",
    "Since we don't have real data yet, let's create a sample dataset that mimics\n",
    "what UCLA YikYak-style posts might look like. This lets us test our pipeline\n",
    "and visualizations.\n",
    "\n",
    "**In a real project**, you would load actual data using:\n",
    "```python\n",
    "df = pd.read_csv('data/processed/features.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9c7992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data for demonstration\n",
    "# This simulates what our processed data would look like\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Generate 1000 sample posts\n",
    "n_posts = 1000\n",
    "\n",
    "# Sample post texts (realistic campus social media content)\n",
    "sample_texts = [\n",
    "    \"love the campus during fall\",\n",
    "    \"finals week is brutal\",\n",
    "    \"parking situation is terrible\",\n",
    "    \"best dining hall on campus\",\n",
    "    \"anyone else stressed about midterms\",\n",
    "    \"go bruins game day\",\n",
    "    \"library is packed cant find seat\",\n",
    "    \"weather is perfect today\",\n",
    "    \"Powell cat spotted again\",\n",
    "    \"need study buddy for chem\"\n",
    "]\n",
    "\n",
    "# Create sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'post_id': [f'post_{i:04d}' for i in range(n_posts)],\n",
    "    \n",
    "    # Timestamps: Random dates over 3 months\n",
    "    'timestamp': pd.date_range(start='2025-10-01', periods=n_posts, freq='2H') + \n",
    "                 pd.to_timedelta(np.random.randint(-30, 30, n_posts), unit='m'),\n",
    "    \n",
    "    # Text: Random selection from sample texts\n",
    "    'text': np.random.choice(sample_texts, n_posts),\n",
    "    'cleaned_text': np.random.choice(sample_texts, n_posts),\n",
    "    \n",
    "    # Upvotes: Log-normal distribution (realistic for social media)\n",
    "    'upvotes': np.random.lognormal(2, 1, n_posts).astype(int),\n",
    "    \n",
    "    # School\n",
    "    'school': 'UCLA'\n",
    "})\n",
    "\n",
    "# Clip upvotes to reasonable range\n",
    "df['upvotes'] = df['upvotes'].clip(0, 200)\n",
    "\n",
    "# Add temporal features\n",
    "df['hour_of_day'] = df['timestamp'].dt.hour\n",
    "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "df['week_of_year'] = df['timestamp'].dt.isocalendar().week\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "# Add text features\n",
    "df['char_count'] = df['cleaned_text'].str.len()\n",
    "df['word_count'] = df['cleaned_text'].str.split().str.len()\n",
    "\n",
    "# Add simple sentiment (random for demo)\n",
    "df['sentiment_score'] = np.random.uniform(-0.3, 0.5, n_posts)\n",
    "\n",
    "# Add engagement label (top 10%)\n",
    "engagement_threshold = df['upvotes'].quantile(0.90)\n",
    "df['is_high_engagement'] = (df['upvotes'] >= engagement_threshold).astype(int)\n",
    "\n",
    "print(f\"âœ“ Created sample dataset with {len(df)} posts\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629eecf0",
   "metadata": {},
   "source": [
    "## Step 2: Initial Data Inspection\n",
    "\n",
    "Let's look at the structure and basic statistics of our data.\n",
    "This helps us understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef2d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "# This gives us a concrete sense of what each row represents\n",
    "print(\"Sample Posts:\")\n",
    "print(\"=\"*80)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a192e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "# Missing data can cause problems in machine learning!\n",
    "print(\"Data Types and Missing Values:\")\n",
    "print(\"=\"*80)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb49cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numerical columns\n",
    "# This shows distributions: mean, median, min, max, etc.\n",
    "print(\"Summary Statistics:\")\n",
    "print(\"=\"*80)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9709fc35",
   "metadata": {},
   "source": [
    "## Step 3: Engagement Distribution\n",
    "\n",
    "Understanding how upvotes are distributed is crucial for our prediction task.\n",
    "Social media engagement typically follows a power-law distribution:\n",
    "most posts get few upvotes, but a small number go viral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot upvote distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of upvotes\n",
    "axes[0].hist(df['upvotes'], bins=50, color='skyblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Number of Upvotes')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Upvotes')\n",
    "axes[0].axvline(df['upvotes'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df[\"upvotes\"].mean():.1f}')\n",
    "axes[0].axvline(df['upvotes'].median(), color='green', linestyle='--',\n",
    "                label=f'Median: {df[\"upvotes\"].median():.1f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot by engagement category\n",
    "df['engagement_category'] = df['is_high_engagement'].map({0: 'Low', 1: 'High'})\n",
    "sns.boxplot(data=df, x='engagement_category', y='upvotes', ax=axes[1])\n",
    "axes[1].set_title('Upvotes by Engagement Category')\n",
    "axes[1].set_xlabel('Engagement Level')\n",
    "axes[1].set_ylabel('Number of Upvotes')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Upvote Statistics:\")\n",
    "print(f\"  Mean: {df['upvotes'].mean():.2f}\")\n",
    "print(f\"  Median: {df['upvotes'].median():.2f}\")\n",
    "print(f\"  Std Dev: {df['upvotes'].std():.2f}\")\n",
    "print(f\"  Min: {df['upvotes'].min()}\")\n",
    "print(f\"  Max: {df['upvotes'].max()}\")\n",
    "print(f\"\\nHigh engagement threshold (90th percentile): {df['upvotes'].quantile(0.90):.1f}\")\n",
    "print(f\"High engagement posts: {df['is_high_engagement'].sum()} ({df['is_high_engagement'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c279de",
   "metadata": {},
   "source": [
    "## Step 4: Temporal Patterns\n",
    "\n",
    "When do people post? When do posts get more engagement?\n",
    "Understanding time-based patterns helps us engineer better features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c59f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posts by hour of day\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Posts by hour\n",
    "hourly_counts = df['hour_of_day'].value_counts().sort_index()\n",
    "axes[0, 0].bar(hourly_counts.index, hourly_counts.values, color='coral')\n",
    "axes[0, 0].set_xlabel('Hour of Day')\n",
    "axes[0, 0].set_ylabel('Number of Posts')\n",
    "axes[0, 0].set_title('Posting Activity by Hour')\n",
    "axes[0, 0].set_xticks(range(0, 24, 2))\n",
    "\n",
    "# 2. Average upvotes by hour\n",
    "hourly_engagement = df.groupby('hour_of_day')['upvotes'].mean().sort_index()\n",
    "axes[0, 1].plot(hourly_engagement.index, hourly_engagement.values, \n",
    "                marker='o', color='purple', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Hour of Day')\n",
    "axes[0, 1].set_ylabel('Average Upvotes')\n",
    "axes[0, 1].set_title('Average Engagement by Hour')\n",
    "axes[0, 1].set_xticks(range(0, 24, 2))\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Posts by day of week\n",
    "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "daily_counts = df['day_of_week'].value_counts().sort_index()\n",
    "axes[1, 0].bar(range(7), daily_counts.values, \n",
    "               color=['lightblue' if i < 5 else 'lightcoral' for i in range(7)])\n",
    "axes[1, 0].set_xlabel('Day of Week')\n",
    "axes[1, 0].set_ylabel('Number of Posts')\n",
    "axes[1, 0].set_title('Posting Activity by Day')\n",
    "axes[1, 0].set_xticks(range(7))\n",
    "axes[1, 0].set_xticklabels(day_names)\n",
    "\n",
    "# 4. Weekend vs Weekday comparison\n",
    "weekend_data = df.groupby('is_weekend').agg({\n",
    "    'upvotes': 'mean',\n",
    "    'post_id': 'count'\n",
    "}).rename(columns={'post_id': 'count'})\n",
    "weekend_labels = ['Weekday', 'Weekend']\n",
    "x = np.arange(len(weekend_labels))\n",
    "width = 0.35\n",
    "axes[1, 1].bar(x - width/2, weekend_data['count'], width, label='Post Count', color='skyblue')\n",
    "ax2 = axes[1, 1].twinx()\n",
    "ax2.bar(x + width/2, weekend_data['upvotes'], width, label='Avg Upvotes', color='orange')\n",
    "axes[1, 1].set_xlabel('Day Type')\n",
    "axes[1, 1].set_ylabel('Post Count', color='skyblue')\n",
    "ax2.set_ylabel('Average Upvotes', color='orange')\n",
    "axes[1, 1].set_title('Weekday vs Weekend Activity')\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(weekend_labels)\n",
    "axes[1, 1].legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ca17a2",
   "metadata": {},
   "source": [
    "## Step 5: Text Characteristics\n",
    "\n",
    "How long are posts? Does length affect engagement?\n",
    "Let's explore the relationship between text features and upvotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text feature analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Character count distribution\n",
    "axes[0, 0].hist(df['char_count'], bins=30, color='lightgreen', edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Character Count')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Distribution of Post Length (Characters)')\n",
    "axes[0, 0].axvline(df['char_count'].mean(), color='red', linestyle='--',\n",
    "                   label=f'Mean: {df[\"char_count\"].mean():.1f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Word count distribution\n",
    "axes[0, 1].hist(df['word_count'], bins=20, color='lightyellow', edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Word Count')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Distribution of Post Length (Words)')\n",
    "axes[0, 1].axvline(df['word_count'].mean(), color='red', linestyle='--',\n",
    "                   label=f'Mean: {df[\"word_count\"].mean():.1f}')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. Length vs Engagement scatter\n",
    "high_eng = df[df['is_high_engagement'] == 1]\n",
    "low_eng = df[df['is_high_engagement'] == 0]\n",
    "axes[1, 0].scatter(low_eng['char_count'], low_eng['upvotes'], \n",
    "                   alpha=0.3, s=20, label='Low Engagement', color='blue')\n",
    "axes[1, 0].scatter(high_eng['char_count'], high_eng['upvotes'],\n",
    "                   alpha=0.5, s=30, label='High Engagement', color='red')\n",
    "axes[1, 0].set_xlabel('Character Count')\n",
    "axes[1, 0].set_ylabel('Upvotes')\n",
    "axes[1, 0].set_title('Post Length vs Engagement')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 4. Sentiment distribution\n",
    "axes[1, 1].hist(df['sentiment_score'], bins=30, color='lightpink', edgecolor='black')\n",
    "axes[1, 1].set_xlabel('Sentiment Score')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Distribution of Sentiment Scores')\n",
    "axes[1, 1].axvline(0, color='black', linestyle='--', label='Neutral')\n",
    "axes[1, 1].axvline(df['sentiment_score'].mean(), color='red', linestyle='--',\n",
    "                   label=f'Mean: {df[\"sentiment_score\"].mean():.3f}')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print correlation\n",
    "print(\"Correlations with Upvotes:\")\n",
    "print(f\"  Character Count: {df['char_count'].corr(df['upvotes']):.3f}\")\n",
    "print(f\"  Word Count: {df['word_count'].corr(df['upvotes']):.3f}\")\n",
    "print(f\"  Sentiment Score: {df['sentiment_score'].corr(df['upvotes']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f50cbe",
   "metadata": {},
   "source": [
    "## Step 6: Feature Correlations\n",
    "\n",
    "Let's create a correlation matrix to see which features are related.\n",
    "This helps us understand:\n",
    "- Which features might be redundant (highly correlated)\n",
    "- Which features might be good predictors (correlated with target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206aa201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features for correlation analysis\n",
    "feature_cols = ['hour_of_day', 'day_of_week', 'is_weekend', 'char_count', \n",
    "                'word_count', 'sentiment_score', 'upvotes', 'is_high_engagement']\n",
    "\n",
    "correlation_matrix = df[feature_cols].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"- Values close to +1: Strong positive correlation\")\n",
    "print(\"- Values close to -1: Strong negative correlation\")\n",
    "print(\"- Values close to 0: No linear relationship\")\n",
    "print(\"\\nLook for features strongly correlated with 'is_high_engagement'!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3ed814",
   "metadata": {},
   "source": [
    "## Step 7: Top Posts Analysis\n",
    "\n",
    "Let's look at the actual content of high-engagement posts.\n",
    "This qualitative analysis can reveal patterns that numbers alone won't show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8123cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top posts by engagement\n",
    "top_posts = df.nlargest(10, 'upvotes')[['text', 'upvotes', 'sentiment_score', \n",
    "                                        'hour_of_day', 'day_of_week']]\n",
    "\n",
    "print(\"Top 10 Most Engaged Posts:\")\n",
    "print(\"=\"*80)\n",
    "for idx, (i, row) in enumerate(top_posts.iterrows(), 1):\n",
    "    day_name = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'][row['day_of_week']]\n",
    "    print(f\"{idx}. [{row['upvotes']} upvotes] {row['text']}\")\n",
    "    print(f\"   Posted: {day_name} at {row['hour_of_day']}:00 | \"\n",
    "          f\"Sentiment: {row['sentiment_score']:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4309933",
   "metadata": {},
   "source": [
    "## Step 8: Summary and Next Steps\n",
    "\n",
    "Based on this exploratory analysis, we can make informed decisions about:\n",
    "\n",
    "1. **Feature Selection**: Which features to include in our model\n",
    "2. **Feature Engineering**: What new features might be useful\n",
    "3. **Model Choice**: What type of model might work best\n",
    "4. **Data Quality**: Whether we need more cleaning or filtering\n",
    "\n",
    "Let's summarize our findings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d7d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EXPLORATORY DATA ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“Š Dataset Overview:\")\n",
    "print(f\"  Total posts: {len(df):,}\")\n",
    "print(f\"  Date range: {df['timestamp'].min().date()} to {df['timestamp'].max().date()}\")\n",
    "print(f\"  Time span: {(df['timestamp'].max() - df['timestamp'].min()).days} days\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Engagement Metrics:\")\n",
    "print(f\"  High engagement threshold: {df['upvotes'].quantile(0.90):.0f} upvotes\")\n",
    "print(f\"  High engagement posts: {df['is_high_engagement'].sum()} ({df['is_high_engagement'].mean()*100:.1f}%)\")\n",
    "print(f\"  Average upvotes: {df['upvotes'].mean():.1f}\")\n",
    "print(f\"  Median upvotes: {df['upvotes'].median():.1f}\")\n",
    "\n",
    "print(\"\\nâ° Temporal Patterns:\")\n",
    "peak_hour = df.groupby('hour_of_day')['upvotes'].mean().idxmax()\n",
    "peak_day = df.groupby('day_of_week')['upvotes'].mean().idxmax()\n",
    "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "print(f\"  Peak engagement hour: {peak_hour}:00\")\n",
    "print(f\"  Peak engagement day: {day_names[peak_day]}\")\n",
    "print(f\"  Weekend posts: {df['is_weekend'].sum()} ({df['is_weekend'].mean()*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nðŸ“ Text Characteristics:\")\n",
    "print(f\"  Average post length: {df['char_count'].mean():.1f} characters\")\n",
    "print(f\"  Average word count: {df['word_count'].mean():.1f} words\")\n",
    "print(f\"  Average sentiment: {df['sentiment_score'].mean():.3f}\")\n",
    "\n",
    "print(\"\\nðŸ” Key Correlations with Engagement:\")\n",
    "correlations = df[feature_cols].corr()['is_high_engagement'].sort_values(ascending=False)\n",
    "for feat, corr in correlations.items():\n",
    "    if feat != 'is_high_engagement':\n",
    "        print(f\"  {feat}: {corr:+.3f}\")\n",
    "\n",
    "print(\"\\nâœ… Next Steps:\")\n",
    "print(\"  1. Train engagement prediction model with these features\")\n",
    "print(\"  2. Perform topic modeling to identify content themes\")\n",
    "print(\"  3. Extract post archetypes from high-engagement content\")\n",
    "print(\"  4. Evaluate model performance and iterate\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2c45d",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Learning Reflection\n",
    "\n",
    "**What did we learn from this EDA?**\n",
    "\n",
    "1. **Data Structure**: We understand the schema and what each field represents\n",
    "2. **Distributions**: We see how engagement follows a power-law (few viral posts)\n",
    "3. **Temporal Patterns**: Posting behavior varies by hour and day\n",
    "4. **Text Features**: Post length and sentiment might influence engagement\n",
    "5. **Correlations**: We identified which features relate to our prediction target\n",
    "\n",
    "**Why is EDA valuable?**\n",
    "\n",
    "- Prevents building models on broken data\n",
    "- Reveals features we might have missed\n",
    "- Helps set realistic expectations for model performance\n",
    "- Guides feature engineering decisions\n",
    "- Often uncovers insights that are valuable on their own!\n",
    "\n",
    "---\n",
    "\n",
    "*Remember: Understanding your data is just as important as building fancy models!*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
